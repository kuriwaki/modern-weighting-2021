---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  echo = FALSE, # don't show "answers"
  comment = "#>"
)
```

# Overview of Modern Survey Weighting

*Shiro Kuriwaki*

*July 28, 2021 Workshop*


<!-- badges: start -->
<!-- badges: end -->

Reweighting to make a dataset representative is a core  operation in data science and survey research, with equally fundamental connection to classical statistical theory. Moreover, the connection between survey inference to causal inference is resurging as selection bias has become a more prominent problem in opt-in surveys, and traditional approaches that focus on researcher-designed sampling become somewhat irrelevant. However, survey weighting is not taught in standard political science graduate training. Here I walk through the core concepts by drawing connections to concepts that are more frequently covered in political science training, like causal inference or machine learning.    I presume a level of familiarity with a 1st year PhD methods class covering bias-variance, OLS, and a bit of research design.

------

## Setup

Download this repo as a **Rstudio Project** (From Remote Repository, Github, `"kuriwaki/modern-weighting-workshop-2021"`).

Load libraries

```{r, echo = TRUE, message=FALSE}
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(scales) # Scale Functions for Visualization

library(survey) # Analysis of Complex Survey Samples
library(autumn) # Fast, Modern, and Tidy-Friendly Iterative Raking
library(lme4) # Linear Mixed-Effects Models using 'Eigen' and S4
```


Read in data as

```{r, echo = TRUE}
poll <- read_rds("data/poll.rds")
pop_micro <- read_rds("data/pop_microdata.rds")
```




## Poststratification

Q: What is the distributon of education in the sample? In the population?

```{r}
poll %>% count(educ) %>% mutate(frac = percent(n / sum(n), accuracy = 1))
pop_micro %>% count(educ) %>% mutate(frac = percent(n / sum(n), accuracy = 1))

```


Q: What are the weights that correct for this imbalance?

```{r}
edu_tgt <- pop_micro %>% count(educ) %>% transmute(educ, pop_frac = n / sum(n))

poll_strat <- poll %>% 
  count(educ) %>% 
  mutate(samp_frac = n / sum(n)) %>% 
  left_join(edu_tgt, by = "educ") %>% 
  mutate(weight0 = pop_frac / samp_frac)

poll_wt <- poll %>% 
  left_join(poll_strat, by = "educ")

poll_wt %>% 
  count(educ, wt = weight0) %>% 
  mutate(wt_frac = n / sum(n))
```


Q: Extension: do the same reweighting but for education and race.

```{r}
xtabs(~ as_factor(educ) + as_factor(race), pop_micro) %>% 
  addmargins()
```


## Raking

Q: What is the distribution of race and education in the survey. 

Now suppose you did NOT know the population _joint_ distribution of race x education, but you knew the _marginals_. Suppose that

* White (1): 72%
* Black (2): 12%
* Hispanic (3) : 10%
* Asian (4): 3%
* Other (5): 3%

and


* HS or Less (1): 40%
* Some College (2): 35%
* 4-Year (3): 15%
* Post-grad (4): 10%


```{r}
target_rake <- list(
  race = c(`1` = 0.72, `2` = 0.12, `3` = 0.10, `4` = 0.03, `5` = 0.03),
  educ = c(`1` = 0.40, `2` = 0.35, `3` = 0.15, `4` = 0.10)
)

poll_rake <- harvest(poll,  target_rake, weight_column = "rake_weight")
```


```{r cces_rake_weights, echo = FALSE}
with(poll_rake, plot(weight, rake_weight, bty = "n", pch = 19, cex = 0.5, xlab = "CCES weights"))
```


Q: What are some issues with doing poststratiifcation everywhere?

## Increased Variance Due to Weighting / Design Effect


Q: What do you need to compute the MSE (or RMSE) of an estimate? What are the components?


Q: Does weighting tend to increase or decrease the standard error of the estimator? The effective sample size? The design effect? Why?


```{r, eval = FALSE}
rwt <- poll_rake$rake_weight

sum(rwt)^2 / sum(rwt^2)

nrow(poll_rake) / (sum(rwt)^2 / sum(rwt^2))

var(rwt)

design_effect(rwt)
```



## How is MRP Different?

Let's treat the values as factors now

```{r, echo = TRUE}
poll_fct <- poll %>% 
  mutate(educ = as_factor(educ), race = as_factor(race))

pop_fct <- pop_micro %>% 
  mutate(educ = as_factor(educ), race = as_factor(race)) 

tgt_fct <- pop_fct %>% 
  count(educ, race)
```


Q: Using a logit, what are the predicted values of the outcome in each of the poststratification cells?

```{r}
fit_logit <- glm(Y ~ educ*race, data = poll_fct, family = binomial)


cells_Ypred <- tgt_fct %>% 
  mutate(Ypred = predict(fit_logit, ., type = "response"))

cells_Ypred
```


Q: What is the "MRP" estimate for Y in the population then?

```{r}
cells_Ypred %>% 
  summarize(Ypred = weighted.mean(Ypred, w = n))
```


Q: What are the issues with a simple logit?



## Propensity Score (IPW) vs. Balancing Score

Q: Using the population data and matching on ID, create a propensity score.

```{r}
pop_sel <- left_join(
  pop_fct,
  transmute(poll_fct, ID, S = 1),
  by = "ID"
) %>% 
  mutate(S = replace_na(S, 0))

fit_sel <- glm(S ~ race + educ + state, pop_sel, family = binomial)

pop_sel %>% 
  mutate(Spred = predict(fit_sel, ., type = "response")) %>% 
  select(ID, race, educ, Spred) %>% 
  sample_n(10)
```


Q: What are the issues in Propensity Score?



Note: Links to Causal Inference and the Weighting vs. Matching Distinction

- Coarsened Exact Matching
- Balance Test Fallacy



Note: Balancing Scores: Entropy Balancing / CBPS

# Takeaways

1. **Survey inference is causal inference** where the treatment is selection
2. Total Error is **Bias^2 + Variance**
3. Many things work "in theory" (asymptotically) but cause **variance problems** in practice: post-stratification, inverse propensity score weighting
4. **Shrinkage** and regularization (random effects, ML) reduces variance at the cost of minimal variance
5. **Balancing scores** guarantees balance on some marginals, while minimizing distance on others.


# References

- Devin Caughey, Adam Berinsky, Susan Chatfield, Erin Hartman,  Eric Schickler, and Jas Sekhon. 2020. "Target Estimation and Adjustment Weighting for Survey Nonresponse and Sampling Bias". _Elements in Quantitative and Computational Methods for the Social Sciences_
- Andrew Gelman. [2007](http://www.stat.columbia.edu/~gelman/research/published/STS226.pdf). "Struggles with Survey Weighting and
Regression Modeling", _Statistical Science_
- Paul Rosenbaum, Donald Rubin. [1983]. "The central role of the propensity score in observational studies for causal effects". _Biometrika_
- Kosuke Imai, Gary King, Elizabeth A Stuart. [2008](https://imai.fas.harvard.edu/research/files/matchse.pdf). "Misunderstandings between experimentalists and observationalists about causal inference", _JRSS A._
  - Also see: Gary King. [2007](https://www.youtube.com/watch?v=rBv39pK1iEs). "Why Propensity Scores Should Not Be Used for Matching", _Methods Colloquium Talk_. (Article with Rich Nielsen).
- Kosuke Imai, Marc Ratkovic. [2014](https://imai.fas.harvard.edu/research/files/CBPS.pdf).  "Covariate balancing propensity score", _JRSS B_.

- Jens Hainmueller. [2012](https://web.stanford.edu/~jhain/Paper/PA2012.pdf). "Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies". _Political Analysis_
