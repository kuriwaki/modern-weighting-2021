---
title: Overview of Modern Survey Weighting
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  echo = FALSE, # don't show "answers"
  comment = "#>"
)
```

_Shiro Kuriwaki_

_Last presented July 28, 2021_

$~$

> "Survey weighting is a mess."  -- Gelman (2007)

$~$


<!-- badges: start -->
<!-- badges: end -->

Reweighting your data to make it representative of a population of interest is a ubiquitous operation in data science and survey research. The procedure has fundamental connections to classical statistical theory. And recently, the connection between survey inference to causal inference is resurging: Selection bias has become prominent in opt-in surveys, and traditional approaches that focus on researcher-designed sampling have become somewhat irrelevant. However, survey weighting is not taught in standard political science graduate training. Here I walk through these core concepts taking the CCES as an example.  I draw connections to concepts which are often covered in political science training, like causal inference or machine learning.    I presume a level of familiarity with a 1st year PhD methods class covering bias-variance, OLS, and some research design.

------

## Setup

Download this repo by [creating](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects) a **Rstudio Project** of it (From Version Control Repository, Github, `"https://github.com/kuriwaki/modern-weighting-2021"`).

Start a new R script (or Rmd if you prefer) in the same repository, root.

Load libraries

```{r, echo = TRUE, message=FALSE}
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(scales) # Scale Functions for Visualization

library(survey) # Analysis of Complex Survey Samples
library(autumn) # Fast, Modern, and Tidy-Friendly Iterative Raking
library(lme4) # Linear Mixed-Effects Models using 'Eigen' and S4
```


Read in data as

```{r, echo = TRUE}
poll <- read_rds("data/poll.rds")
frame <- read_rds("data/pop_microdata.rds")
```


Note: how to read this document. The preview on github is a compiled version of README.Rmd. The README.Rmd has the code to produce all the results, but the preview only shows the results. If you need to check the answers, you can check the Rmd. Alternatively, you can convert the solutions as a R script with `knitr::purl("README.Rmd")`.


$~$

## The Power and Simplicity of Poststratification

> "The purpose of poststratification is to correct for known differences between sample and population." --- Gelman (2007)

Q: What is the distribution of education in the sample? In the population?

```{r}
poll %>% count(educ) %>% mutate(frac = percent(n / sum(n), accuracy = 1))
frame %>% count(educ) %>% mutate(frac = percent(n / sum(n), accuracy = 1))

```


Q: What are the weights that correct for this imbalance?

```{r}
edu_tgt <- frame %>% 
  count(educ) %>% 
  transmute(educ, pop_frac = n / sum(n))

poll_strat <- poll %>% 
  count(educ) %>% 
  mutate(samp_frac = n / sum(n)) %>% 
  left_join(edu_tgt, by = "educ") %>% 
  mutate(weight1 = pop_frac / samp_frac)

poll_wt <- poll %>% 
  left_join(poll_strat, by = "educ")

poll_wt %>% 
  count(educ, wt = weight1) %>% 
  mutate(wt_frac = n / sum(n))
```

Q: What is the weighted proportion of `Y`? Is that closer to the population proportion of Y than the unweighted proportion?

Q: Extension: Explain how you would do the same reweighting but for education and race.

- What is the distribution of race and education in the population?

```{r}
xtabs(~ as_factor(educ) + as_factor(race), frame) %>% 
  prop.table() %>% 
  round(digits = 2) %>% 
  addmargins()
```

- In the survey?

```{r}
xtabs(~ as_factor(educ) + as_factor(race), poll) %>% 
  prop.table() %>% 
  round(digits = 2) %>% 
  addmargins()
```


Q: Estimate those weights. How does it differ from the previous weights?

```{r}
edurace_tgt <- frame %>% 
  count(educ, race) %>% 
  transmute(educ, race, pop_frac = n / sum(n))

poll_strat2 <- poll %>% 
  count(educ, race) %>% 
  mutate(samp_frac = n / sum(n)) %>% 
  left_join(edurace_tgt, by = c("educ", "race")) %>% 
  mutate(weight2 = pop_frac / samp_frac)

poll_wt2 <- poll %>% 
  left_join(poll_strat2, by = c("educ", "race"))

compare_ps <- left_join(
  poll_wt, 
  select(poll_wt2, ID, weight2),
  by = "ID")
```


```{r twowayps}
with(compare_ps, 
     plot(weight1, weight2, bty = "n", pch = 19, cex = 0.5, 
          xlab = "Poststrat weights on education", 
          ylab = "Poststrat weights on educ x race")
)
```


Q: What are some roadblocks / issues with doing poststratification everywhere?

$~$

## Raking: an approximation to full poststratification

Q: Now suppose you did NOT know the population _joint_ distribution of race x education, but you knew the _marginals_. Suppose that

* White (1): 72%
* Black (2): 12%
* Hispanic (3) : 10%
* Asian (4): 3%
* Other (5): 3%

and


* HS or Less (1): 40%
* Some College (2): 35%
* 4-Year (3): 15%
* Post-grad (4): 10%


Using raking, create weights that satisfy these marginal distributions. 

```{r}
target_rake <- list(
  race = c(`1` = 0.72, `2` = 0.12, `3` = 0.10, `4` = 0.03, `5` = 0.03),
  educ = c(`1` = 0.40, `2` = 0.35, `3` = 0.15, `4` = 0.10)
)

poll_rake <- harvest(data = poll, target = target_rake, weight_column = "rake_weight")
```


```{r cces_rake_weights, echo = FALSE}
ps_rk <- left_join(
  compare_ps, 
  select(poll_rake, ID, matches("weight"))
)

par(mfrow = c(1, 2))
plot(ps_rk$weight2, 
     ps_rk$rake_weight, 
     bty = "n", 
     pch = 19, 
     cex = 0.5, 
     asp = 1,
     xlab = "Poststrat weights",
     ylab = "Rake weights",
     ylim = c(0, 10),
     xlim = c(0, 10))
abline(0, 1, lty = "dashed")

plot(ps_rk$weight, 
     ps_rk$rake_weight, 
     bty = "n", 
     pch = 19, 
     cex = 0.5,
     asp = 1,
     xlab = "CCES weights",
     ylab = "Rake weights",
     ylim = c(0, 10))
```


Q: Intuitively, what is the assumption we need to make for raking to give the same answer as poststratification?

$~$

## The Curse of Increased Variance due to Weighting

> "It is not always clear how to use weights in estimating anything more complicated than a simple mean or ratios, and standard errors are tricky even with simple weighted means. " --- Gelman (2007)

Q: What is a standard error of a survey estimator? How is it different from the standard deviation / variance of your estimates?

Q: What do you need to compute the MSE (or RMSE) of an estimate? What are the components?


Q: Does weighting tend to increase or decrease the standard error of the estimator? The effective sample size? The design effect? Why?


```{r, eval = FALSE}
rwt <- poll_rake$rake_weight

sum(rwt)^2 / sum(rwt^2)

nrow(poll_rake) / (sum(rwt)^2 / sum(rwt^2))

var(rwt)

design_effect(rwt)
```

$~$

## How is MRP Different?

> "Regression modeling is a potentially attractive alter- native to weighting. In practice, however, the poten- tial for large numbers of interactions can make regres- sion adjustments highly variable. This paper reviews the motivation for hierarchical regression, combined with poststratification, as a strategy for correcting for differences between sample and population. --- Gelman (2007)



Let's treat the values as factors now

```{r, echo = TRUE}
poll_fct <- poll %>% 
  mutate(educ = as_factor(educ), race = as_factor(race))

frame_fct <- frame %>% 
  mutate(educ = as_factor(educ), race = as_factor(race)) 

tgt_fct <- frame_fct %>% 
  count(educ, race)
```


Q: Using a logit, what are the predicted values of the outcome in each of the poststratification cells?

```{r}
fit_logit <- glm(Y ~ educ*race, data = poll_fct, family = binomial)


cells_Ypred <- tgt_fct %>% 
  mutate(Ypred = predict(fit_logit, ., type = "response"))

cells_Ypred
```


Q: What is the "MRP" estimate for Y in the population then?

```{r}
cells_Ypred %>% 
  summarize(Ypred = weighted.mean(Ypred, w = n))
```


Q: What are the issues with a simple logit?

$~$

## Why balancing score are better than inverse propensity weighting

> "Contrary to what is assumed by many theoretical statisticians, survey weights are not in general equal to inverse probabilities of selection but rather are typically constructed based on a combination of prob- ability calculations and nonresponse adjustments." --- Gelman (2007)


Q: Using the population data and matching on ID, create a propensity score.

```{r}
frame_sel <- left_join(
  frame_fct,
  transmute(poll_fct, ID, S = 1),
  by = "ID") %>% 
  mutate(S = replace_na(S, 0))

fit_sel <- glm(S ~ race + educ + state, frame_sel, family = binomial)

frame_sel %>% 
  mutate(Spred = predict(fit_sel, ., type = "response")) %>% 
  select(ID, race, educ, Spred) %>% 
  sample_n(10)
```


Q: What are the issues in Propensity Score?


Note: Links to Causal Inference and the Weighting vs. Matching Distinction

- Coarsened Exact Matching
- Balance Test Fallacy


Note: Balancing Scores: Entropy Balancing / CBPS

# Takeaways

1. **Survey inference is causal inference** where the treatment is selection
2. Total Error is **Bias^2 + Variance**
3. Many things work "in theory" (asymptotically) but cause **variance problems** in practice: post-stratification, inverse propensity score weighting
4. **Shrinkage** and regularization (random effects, ML) reduces variance at the cost of minimal variance
5. **Balancing scores** guarantees balance on some marginals, while minimizing distance on others.


# References

- Devin Caughey, Adam Berinsky, Sara Chatfield, Erin Hartman,  Eric Schickler, and Jas Sekhon. [2020](https://doi.org/10.1017/9781108879217). "Target Estimation and Adjustment Weighting for Survey Nonresponse and Sampling Bias". _Elements in Quantitative and Computational Methods for the Social Sciences_
- Andrew Gelman. [2007](http://www.stat.columbia.edu/~gelman/research/published/STS226.pdf). "Struggles with Survey Weighting and
Regression Modeling", _Statistical Science_
- Paul Rosenbaum, Donald Rubin. [1983]. "The central role of the propensity score in observational studies for causal effects". _Biometrika_
- Kosuke Imai, Gary King, Elizabeth Stuart. [2008](https://imai.fas.harvard.edu/research/files/matchse.pdf). "Misunderstandings between experimentalists and observationalists about causal inference", _JRSS A._
- Also see: Gary King. [2007](https://www.youtube.com/watch?v=rBv39pK1iEs). "Why Propensity Scores Should Not Be Used for Matching", _Methods Colloquium Talk_. (Article with Rich Nielsen).
- Kosuke Imai, Marc Ratkovic. [2014](https://imai.fas.harvard.edu/research/files/CBPS.pdf).  "Covariate balancing propensity score", _JRSS B_.

- Jens Hainmueller. [2012](https://web.stanford.edu/~jhain/Paper/PA2012.pdf). "Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies". _Political Analysis_
